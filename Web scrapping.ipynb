{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_url = 'http://shakespeare.mit.edu/'\n",
    "\n",
    "response = requests.get(main_url)\n",
    "main_soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "td_elements = main_soup.find_all('td', attrs={'valign': 'BASELINE'})\n",
    "\n",
    "# print(f\"The number of td_elements are {len(td_elements)}\")\n",
    "\n",
    "for td_element in td_elements:\n",
    "    links = td_element.find_all('a')   \n",
    "    for link in links:\n",
    "        href = link['href']\n",
    "        # print(href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poetry/sonnets.html\n",
      "Poetry/LoversComplaint.html\n",
      "Poetry/RapeOfLucrece.html\n",
      "Poetry/VenusAndAdonis.html\n",
      "Poetry/elegy.html\n"
     ]
    }
   ],
   "source": [
    "# getting only poetry\n",
    "poems = td_elements[-1]\n",
    "links = poems.find_all('a')   \n",
    "for link in links:\n",
    "    href = link['href']\n",
    "    print(href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting sonnet links\n",
    "sonnet_url = main_url + links[0]['href']\n",
    "\n",
    "response = requests.get(sonnet_url)\n",
    "main_soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "link_elements = main_soup.find_all('a')\n",
    "poem_links = []\n",
    "for link in link_elements[1:]:\n",
    "    href = link['href']\n",
    "    poem_link = 'http://shakespeare.mit.edu/Poetry/' + href\n",
    "    poem_links.append(poem_link)    \n",
    "\n",
    "output_file = 'Poems\\William Shakespeare\\Sonnet.txt'\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as file:\n",
    "    for link in poem_links:\n",
    "        response = requests.get(link)        \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        blockquote_element = soup.find('blockquote')\n",
    "        text = blockquote_element.get_text()        \n",
    "        file.write(text)\n",
    "        file.write('\\n')\n",
    "\n",
    "print(f\"Scraping completed. The texts are saved in '{output_file}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting lovers_complaint links\n",
    "lovers_complaint_url = main_url + links[1]['href']\n",
    "\n",
    "response = requests.get(lovers_complaint_url)\n",
    "main_soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "output_file = 'Poems\\William Shakespeare\\Lovers complaint.txt'\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as file:\n",
    "    response = requests.get(lovers_complaint_url)        \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    blockquote_elements = soup.find_all('blockquote')\n",
    "    for blockquote_element in blockquote_elements:\n",
    "        text = blockquote_element.get_text()        \n",
    "        file.write(text)\n",
    "        file.write('\\n')\n",
    "\n",
    "print(f\"Scraping completed. The texts are saved in '{output_file}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting rape_of_lucree links\n",
    "rape_of_lucrece_url = main_url + links[2]['href']\n",
    "\n",
    "response = requests.get(rape_of_lucrece_url)\n",
    "main_soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "output_file = 'Poems\\William Shakespeare\\Rape of Lucrece.txt'\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as file:\n",
    "    response = requests.get(rape_of_lucrece_url)        \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    blockquote_elements = soup.find_all('blockquote')\n",
    "    for blockquote_element in blockquote_elements:\n",
    "        text = blockquote_element.get_text()        \n",
    "        file.write(text)\n",
    "        file.write('\\n')\n",
    "\n",
    "print(f\"Scraping completed. The texts are saved in '{output_file}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting venus_and_adonis links\n",
    "venus_and_adonis_url = main_url + links[3]['href']\n",
    "\n",
    "response = requests.get(venus_and_adonis_url)\n",
    "main_soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "output_file = 'Poems\\William Shakespeare\\Venus and Adonis.txt'\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as file:\n",
    "    response = requests.get(venus_and_adonis_url)        \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    blockquote_elements = soup.find_all('blockquote')\n",
    "    for blockquote_element in blockquote_elements:\n",
    "        text = blockquote_element.get_text()        \n",
    "        file.write(text)\n",
    "        file.write('\\n')\n",
    "\n",
    "print(f\"Scraping completed. The texts are saved in '{output_file}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# links for funeral_elegy:\n",
    "funeral_elegy_url = main_url + links[4]['href']\n",
    "\n",
    "response = requests.get(funeral_elegy_url)\n",
    "main_soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "output_file = 'Poems\\William Shakespeare\\A funeral elegy.txt'\n",
    "\n",
    "td_element = main_soup.find('td')\n",
    "text = td_element.get_text()\n",
    "text = re.sub(r'\\b\\d+\\b', '', text)\n",
    "\n",
    "lines = text.split('\\n')\n",
    "\n",
    "# for line in lines:\n",
    "#     print(line.strip())\n",
    "with open(output_file, 'w') as file:\n",
    "    for line in lines:\n",
    "        file.write(line.strip() + '\\n')\n",
    "        \n",
    "print(f\"Scraping completed. The texts are saved in '{output_file}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging all poems into one file\n",
    "folder_path = \"Poems/William Shakespeare\"\n",
    "output_file = \"Poems/William Shakespeare/Shakespeare's poems.txt\"\n",
    "\n",
    "with open(output_file, 'w') as outfile:\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.txt'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'r') as infile:\n",
    "                outfile.write(infile.read())\n",
    "            outfile.write('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slyvia plath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_url = 'https://mypoeticside.com/poets/sylvia-plath-poems'\n",
    "\n",
    "# response = requests.get(main_url)\n",
    "# main_soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# urls = main_soup.find_all('a', attrs={'rel': 'nofollow'})\n",
    "# urls = urls[:230]\n",
    "\n",
    "# for url in urls:\n",
    "#     href = url['href']\n",
    "#     print(href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poems merged and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "main_url = 'https://mypoeticside.com/poets/sylvia-plath-poems'\n",
    "\n",
    "response = requests.get(main_url)\n",
    "main_soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "urls = main_soup.find_all('a', attrs={'rel': 'nofollow'})\n",
    "urls = urls[:230]\n",
    "\n",
    "poems = []\n",
    "\n",
    "for url in urls:\n",
    "    poem_url = 'https:' + url['href']\n",
    "    response = requests.get(poem_url)\n",
    "    poem_soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    p_element = poem_soup.find('p')\n",
    "    poem_text = p_element.get_text()\n",
    "\n",
    "    poems.append(poem_text.strip())\n",
    "\n",
    "merged_poems = '\\n\\n'.join(poems)\n",
    "\n",
    "output_file = 'Poems\\Slyvia Plath\\sylvia_plath_merged.txt'\n",
    "with open(output_file, 'w', encoding='utf-8') as file:\n",
    "    file.write(merged_poems)\n",
    "\n",
    "print('Poems merged and saved successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_url = 'https://mypoeticside.com/poets/sylvia-plath-poems'\n",
    "\n",
    "# response = requests.get(main_url)\n",
    "# main_soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "\n",
    "# for url in urls:\n",
    "#     url = 'https:' + url['href']\n",
    "#     # print(url)\n",
    "\n",
    "#     response = requests.get(url)\n",
    "#     main_soup = BeautifulSoup(response.content, 'html.parser')\n",
    "#     p_element = main_soup.find('p')\n",
    "#     text = p_element.get_text()\n",
    "\n",
    "#     lines = text.split('\\n')\n",
    "#     for l in lines:\n",
    "#         print(l)\n",
    "# # trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is this, behind this veil, is it ugly, is it beautiful?\n",
      "It is shimmering, has it breasts, has it edges?\n",
      "\n",
      "I am sure it is unique, I am sure it is what I want.\n",
      "When I am quiet at my cooking I feel it looking, I feel it thinking\n",
      "\n",
      "'Is this the one I am too appear for,\n",
      "Is this the elect one, the one with black eye-pits and a scar?\n",
      "\n",
      "Measuring the flour, cutting off the surplus,\n",
      "Adhering to rules, to rules, to rules.\n",
      "\n",
      "Is this the one for the annunciation?\n",
      "My god, what a laugh!'\n",
      "\n",
      "But it shimmers, it does not stop, and I think it wants me.\n",
      "I would not mind if it were bones, or a pearl button.\n",
      "\n",
      "I do not want much of a present, anyway, this year.\n",
      "After all I am alive only by accident.\n",
      "\n",
      "I would have killed myself gladly that time any possible way.\n",
      "Now there are these veils, shimmering like curtains,\n",
      "\n",
      "The diaphanous satins of a January window\n",
      "White as babies' bedding and glittering with dead breath. O ivory!\n",
      "\n",
      "It must be a tusk there, a ghost column.\n",
      "Can you not see I do not mind what it is.\n",
      "\n",
      "Can you not give it to me?\n",
      "Do not be ashamed--I do not mind if it is small.\n",
      "\n",
      "Do not be mean, I am ready for enormity.\n",
      "Let us sit down to it, one on either side, admiring the gleam,\n",
      "\n",
      "The glaze, the mirrory variety of it.\n",
      "Let us eat our last supper at it, like a hospital plate.\n",
      "\n",
      "I know why you will not give it to me,\n",
      "You are terrified\n",
      "\n",
      "The world will go up in a shriek, and your head with it,\n",
      "Bossed, brazen, an antique shield,\n",
      "\n",
      "A marvel to your great-grandchildren.\n",
      "Do not be afraid, it is not so.\n",
      "\n",
      "I will only take it and go aside quietly.\n",
      "You will not even hear me opening it, no paper crackle,\n",
      "\n",
      "No falling ribbons, no scream at the end.\n",
      "I do not think you credit me with this discretion.\n",
      "\n",
      "If you only knew how the veils were killing my days.\n",
      "To you they are only transparencies, clear air.\n",
      "\n",
      "But my god, the clouds are like cotton.\n",
      "Armies of them. They are carbon monoxide.\n",
      "\n",
      "Sweetly, sweetly I breathe in,\n",
      "Filling my veins with invisibles, with the million\n",
      "\n",
      "Probable motes that tick the years off my life.\n",
      "You are silver-suited for the occasion. O adding machine-----\n",
      "\n",
      "Is it impossible for you to let something go and have it go whole?\n",
      "Must you stamp each piece purple,\n",
      "\n",
      "Must you kill what you can?\n",
      "There is one thing I want today, and only you can give it to me.\n",
      "\n",
      "It stands at my window, big as the sky.\n",
      "It breathes from my sheets, the cold dead center\n",
      "\n",
      "Where split lives congeal and stiffen to history.\n",
      "Let it not come by the mail, finger by finger.\n",
      "\n",
      "Let it not come by word of mouth, I should be sixty\n",
      "By the time the whole of it was delivered, and to numb to use it.\n",
      "\n",
      "Only let down the veil, the veil, the veil.\n",
      "If it were death\n",
      "\n",
      "I would admire the deep gravity of it, its timeless eyes.\n",
      "I would know you were serious.\n",
      "\n",
      "There would be a nobility then, there would be a birthday.\n",
      "And the knife not carve, but enter\n",
      "\n",
      "Pure and clean as the cry of a baby,\n",
      "And the universe slide from my side.\n"
     ]
    }
   ],
   "source": [
    "p_element = main_soup.find('p')\n",
    "text = p_element.get_text()\n",
    "\n",
    "lines = text.split('\\n')\n",
    "for l in lines:\n",
    "    print(l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
